{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "class ModelOperatorOllama():\n",
    "    def __init__(self):\n",
    "        self.url = 'http://127.0.0.1:11435/api/'\n",
    "        self.model_list = self.list_models()\n",
    "        \n",
    "        # db_configs\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def generate_response(self,model,system_prompt,prompt,format=None):\n",
    "        \"\"\"\n",
    "        Sends a request to the LLM API and returns the response.\n",
    "        \"\"\"\n",
    "        \n",
    "        if model in self.model_list:\n",
    "            self.model = model\n",
    "        else:\n",
    "            raise ValueError(f\"Model '{model}' not provided or not found in available models: {self.model_list}\")\n",
    "        \n",
    "        url=\"http://127.0.0.1:11435/api/chat\"\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"keep_alive\": 0,\n",
    "            \"messages\": [\n",
    "                {'role':'system',\n",
    "                'content':system_prompt\n",
    "                },\n",
    "                {'role':'user',\n",
    "                'content':prompt}\n",
    "                ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        if format:\n",
    "            payload.update(format)\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        \n",
    "        response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "        \n",
    "        # get generation timestamp\n",
    "        timestamp = datetime.datetime.now().isoformat()\n",
    "        response_json = response.json()\n",
    "        response_json.update({'timestamp':timestamp})\n",
    "        \n",
    "\n",
    "        return response_json\n",
    "        \n",
    "    def list_models(self):\n",
    "        \n",
    "        response = requests.get(f'{self.url}tags')\n",
    "        model_dict = {\n",
    "            model['name']: {'model_name': model['name'],\n",
    "                            'param_size': model['details']['parameter_size'],\n",
    "                            'quant_level': model['details']['quantization_level']} for model in response.json()['models']\n",
    "    }\n",
    "        return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmp = ModelOperatorOllama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmp.generate_response('llama3.2:latest','','what is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2:latest',\n",
       " 'created_at': '2025-02-01T15:21:52.1530349Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': \"I don't have any information about you, so I'm not sure what your name is. We just started our conversation, and I don't have any prior knowledge or data about you. Would you like to tell me your name, though?\"},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 2904456100,\n",
       " 'load_duration': 1591682300,\n",
       " 'prompt_eval_count': 30,\n",
       " 'prompt_eval_duration': 151000000,\n",
       " 'eval_count': 50,\n",
       " 'eval_duration': 698000000,\n",
       " 'timestamp': '2025-02-01T15:21:52.153541'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json['load_duration'] = round(response_json['load_duration']/(10**9),2)\n",
    "response_json['prompt_eval_duration'] = round(response_json['prompt_eval_duration']/(10**9),2)\n",
    "response_json['eval_duration'] = round(response_json['eval_duration']/(10**9),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(2904456100*(10**-9),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as psql\n",
    "\n",
    "# connects to db\n",
    "connection = psql.connect(user = 'llmp',\n",
    "                        password = 'Akechi21234',\n",
    "                        host = '127.0.0.1',\n",
    "                        port = '5432',\n",
    "                        database = 'llmp_db')\n",
    "\n",
    "# cursor to run queries and operations on db\n",
    "# cursor = connection.cursor()\n",
    "\n",
    "# query example\n",
    "# cursor.execute(\"SELECT 1 FROM llmp_db\")\n",
    "\n",
    "# get results from query\n",
    "# data = cursor.fetchmany()\n",
    "# print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table_query = \"DROP TABLE IF EXISTS generation_history;\"\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(drop_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.autocommit = True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS generation_history (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            model TEXT,\n",
    "            system_prompt TEXT,\n",
    "            prompt TEXT,\n",
    "            generated_text TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            test TEXT\n",
    "        );\n",
    "        \"\"\"\n",
    "cursor.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "temp_conn = psql.connect(user = 'llmp',\n",
    "                        password = 'Akechi21234',\n",
    "                        host = '127.0.0.1',\n",
    "                        port = '5432',\n",
    "                        database = 'llmp_db')\n",
    "\n",
    "temp_conn.autocommit = True\n",
    "temp_cur = temp_conn.cursor()\n",
    "database = 'llmp_db'\n",
    " # Check if database exists\n",
    "temp_cur.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{database}'\")\n",
    "exists = temp_cur.fetchone()\n",
    "if exists:\n",
    "    print(1)\n",
    "else:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import psycopg2 as psql\n",
    "# with db connection\n",
    "\n",
    "class ModelOperatorOllama():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Ollama configs\n",
    "        self.url = 'http://127.0.0.1:11435/api/'\n",
    "        self.model_list = self.list_models()\n",
    "        \n",
    "        # db configs\n",
    "        self.db_user = 'llmp'\n",
    "        self.db_password = 'Akechi21234'\n",
    "        self.db_host = '127.0.0.1'\n",
    "        self.db_port = '5432'\n",
    "        self.db_database = 'llmp_db'\n",
    "        \n",
    "        # db connection\n",
    "        self.connection = self.connect_to_db()\n",
    "        self.cursor = self.connection.cursor()\n",
    "        # create table if not exists\n",
    "        self.create_gen_hist_table()\n",
    "        \n",
    "        \n",
    "    def connect_to_db(self):\n",
    "        \"\"\"\n",
    "        Verify if database exists, if not, creates it.\n",
    "        Connects to the database and returns the connection object.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            # verify if db exists\n",
    "            tmp_connection = psql.connect(user = self.db_user,\n",
    "                            password = self.db_password,\n",
    "                            host = self.db_host,\n",
    "                            port = self.db_port,\n",
    "                            database = self.db_database)\n",
    "            \n",
    "            tmp_connection.autocommit = True\n",
    "            tmp_cursor = tmp_connection.cursor()\n",
    "            tmp_cursor.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{self.db_database}'\")\n",
    "            exists = tmp_cursor.fetchone()\n",
    "            \n",
    "            # if doesn't exist, create it\n",
    "            if not exists:\n",
    "                print(f\"Database '{self.db_database}' not found. Creating it...\")\n",
    "                tmp_cursor.execute(f\"CREATE DATABASE {self.db_database}\")\n",
    "                \n",
    "            tmp_cursor.close()\n",
    "            tmp_connection.close()\n",
    "            \n",
    "            # conenct to db\n",
    "            connection = psql.connect(\n",
    "                dbname=self.db_database,\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                host=self.db_host,\n",
    "                port=self.db_port\n",
    "            )\n",
    "            print(f\"Connected to database: {self.db_database}\")\n",
    "            return connection\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Database connection failed: {e}\")\n",
    "            raise   \n",
    "        \n",
    "    def create_gen_hist_table(self):\n",
    "        \"\"\"\n",
    "        Checks if gen_hist table exists, if not creates it.\n",
    "        \"\"\"\n",
    "        table_creation_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS generation_history (\n",
    "            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
    "            gen_id TEXT,\n",
    "            gen_timestamp TEXT,\n",
    "            model TEXT,\n",
    "            system_prompt TEXT,\n",
    "            prompt TEXT,\n",
    "            gent_text TEXT,\n",
    "            prompt_eval_count INT,\n",
    "            eval_count INT,\n",
    "            load_duration FLOAT,\n",
    "            prompt_eval_duration FLOAT,\n",
    "            eval_duration FLOAT\n",
    "        );\n",
    "        \"\"\"\n",
    "        self.cursor.execute(table_creation_query)\n",
    "        \n",
    "        \n",
    "    def save_to_db(self, generation_data):\n",
    "        \"\"\"\n",
    "        Saves the generated response to PostgreSQL.\n",
    "        \n",
    "        Parameters:\n",
    "        - generation_data (dict): JSON object containing generation details.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Map JSON keys to table columns\n",
    "            db_columns = {\n",
    "                \"gen_id\": generation_data.get(\"gen_id\"),\n",
    "                \"gen_timestamp\": generation_data.get(\"timestamp\"),\n",
    "                \"model\": generation_data.get(\"model\"),\n",
    "                \"system_prompt\": generation_data.get(\"system_prompt\"),\n",
    "                \"prompt\": generation_data.get(\"prompt\"),\n",
    "                \"gent_text\": generation_data.get(\"message\", {}).get(\"content\"),\n",
    "                \"prompt_eval_count\": generation_data.get(\"prompt_eval_count\"),\n",
    "                \"eval_count\": generation_data.get(\"eval_count\"),\n",
    "                \"load_duration\": generation_data.get(\"load_duration\"),\n",
    "                \"prompt_eval_duration\": generation_data.get(\"prompt_eval_duration\"),\n",
    "                \"eval_duration\": generation_data.get(\"eval_duration\"),\n",
    "            }\n",
    "\n",
    "            # Generate dynamic SQL query\n",
    "            columns = \", \".join(db_columns.keys())\n",
    "            placeholders = \", \".join([\"%s\"] * len(db_columns))\n",
    "            values = tuple(db_columns.values())\n",
    "\n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO generation_history ({columns})\n",
    "            VALUES ({placeholders});\n",
    "            \"\"\"\n",
    "\n",
    "            # Execute and commit the query\n",
    "            self.cursor.execute(insert_query, values)\n",
    "            self.connection.commit()\n",
    "            print(\"Generation saved to database.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.connection.rollback()\n",
    "            print(f\"Failed to save generation to database: {e}\")\n",
    "        \n",
    "\n",
    "    def generate_response(self,model,system_prompt,prompt,format=None):\n",
    "        \"\"\"\n",
    "        Sends a request to the LLM API and returns the response.\n",
    "        \"\"\"\n",
    "        timestamp = datetime.datetime.now().isoformat()\n",
    "        timestamp = str(timestamp)\n",
    "        if model in self.model_list:\n",
    "            self.model = model\n",
    "        else:\n",
    "            raise ValueError(f\"Model '{model}' not provided or not found in available models: {self.model_list}\")\n",
    "        \n",
    "        url=\"http://127.0.0.1:11435/api/chat\"\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"keep_alive\": 0,\n",
    "            \"messages\": [\n",
    "                {'role':'system',\n",
    "                'content':system_prompt\n",
    "                },\n",
    "                {'role':'user',\n",
    "                'content':prompt}\n",
    "                ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        if format:\n",
    "            payload.update(format)\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        \n",
    "        response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "        \n",
    "        # get generation timestamp\n",
    "        \n",
    "        response_json = response.json()\n",
    "        \n",
    "        response_json.update({'system_prompt':system_prompt})\n",
    "        response_json.update({'prompt':prompt})\n",
    "        response_json.update({'timestamp':timestamp})\n",
    "        response_json['load_duration'] = round(response_json['load_duration']/(10**9),2)\n",
    "        response_json['prompt_eval_duration'] = round(response_json['prompt_eval_duration']/(10**9),2)\n",
    "        response_json['eval_duration'] = round(response_json['eval_duration']/(10**9),2)\n",
    "        response_json['gen_id'] = f'{response_json['model']}_{response_json['timestamp']}'\n",
    "        \n",
    "        print('saving data')\n",
    "        self.save_to_db(response_json)\n",
    "\n",
    "        return response_json\n",
    "        \n",
    "    def list_models(self):\n",
    "        \n",
    "        response = requests.get(f'{self.url}tags')\n",
    "        model_dict = {\n",
    "            model['name']: {'model_name': model['name'],\n",
    "                            'param_size': model['details']['parameter_size'],\n",
    "                            'quant_level': model['details']['quantization_level']} for model in response.json()['models']\n",
    "    }\n",
    "        return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database: llmp_db\n",
      "saving data\n",
      "Generation saved to database.\n"
     ]
    }
   ],
   "source": [
    "from src.model_operator.model_operator import ModelOperatorOllama\n",
    "llmp = ModelOperatorOllama()\n",
    "response = llmp.generate_response('llama3.2:latest','','what is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2:latest',\n",
       " 'created_at': '2025-02-01T17:10:24.4045472Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': \"I don't have any information about your name. I'm a large language model, I don't have the ability to store or recall personal details about individual users. Each time you interact with me, it's a new conversation and I start from a blank slate. Would you like to tell me your name?\"},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 3146740200,\n",
       " 'load_duration': 1.61,\n",
       " 'prompt_eval_count': 30,\n",
       " 'prompt_eval_duration': 0.18,\n",
       " 'eval_count': 63,\n",
       " 'eval_duration': 0.89,\n",
       " 'system_prompt': '',\n",
       " 'prompt': 'what is my name?',\n",
       " 'timestamp': '2025-02-01T17:10:21.256455',\n",
       " 'gen_id': 'llama3.2:latest_2025-02-01T17:10:21.256455'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.get(\"eval_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db(self):\n",
    "        \"\"\"Connects to PostgreSQL and creates the database if it doesn't exist.\"\"\"\n",
    "        try:\n",
    "            # Connect to default 'postgres' database to check if target DB exists\n",
    "            temp_conn = psycopg2.connect(\n",
    "                dbname=\"postgres\",\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                host=self.db_host,\n",
    "                port=self.db_port\n",
    "            )\n",
    "            temp_conn.autocommit = True\n",
    "            temp_cur = temp_conn.cursor()\n",
    "\n",
    "            # Check if database exists\n",
    "            temp_cur.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{self.db_name}'\")\n",
    "            exists = temp_cur.fetchone()\n",
    "\n",
    "            if not exists:\n",
    "                print(f\"Database '{self.db_name}' not found. Creating it...\")\n",
    "                temp_cur.execute(f\"CREATE DATABASE {self.db_name}\")\n",
    "\n",
    "            temp_cur.close()\n",
    "            temp_conn.close()\n",
    "\n",
    "            # Now connect to the actual database\n",
    "            conn = psycopg2.connect(\n",
    "                dbname=self.db_name,\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                host=self.db_host,\n",
    "                port=self.db_port\n",
    "            )\n",
    "            print(f\"Connected to database: {self.db_name}\")\n",
    "            return conn\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Database connection failed: {e}\")\n",
    "            raise\n",
    "        \n",
    "        \n",
    "def create_table_if_not_exists(self):\n",
    "        \"\"\"Ensures the generation history table exists in the database.\"\"\"\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS generation_history (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            model TEXT,\n",
    "            system_prompt TEXT,\n",
    "            prompt TEXT,\n",
    "            generated_text TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        );\n",
    "        \"\"\"\n",
    "        self.cur.execute(create_table_query)\n",
    "        self.conn.commit()\n",
    "        print(\"Table 'generation_history' is ready.\")\n",
    "        \n",
    "\n",
    "def save_to_db(self, model, system_prompt, prompt, generated_text):\n",
    "        \"\"\"Saves the generated response to PostgreSQL.\"\"\"\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO generation_history (model, system_prompt, prompt, generated_text)\n",
    "        VALUES (%s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "        self.cur.execute(insert_query, (model, system_prompt, prompt, generated_text))\n",
    "        self.conn.commit()\n",
    "        print(\"Generation saved to database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x000001FC25B99250; dsn: 'user=llmp password=xxx dbname=llmp_db host=127.0.0.1 port=5432', closed: 0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import psycopg2\n",
    "\n",
    "class ModelOperatorOllama():\n",
    "    def __init__(self):\n",
    "        # PostgreSQL connection settings\n",
    "        self.db_name = \"llmp_db\"\n",
    "        self.db_user = \"llmp\"\n",
    "        self.db_password = \"Akechi21234\"  # Replace with actual password\n",
    "        self.db_host = \"127.0.0.1\"\n",
    "        self.db_port = \"5432\"\n",
    "\n",
    "        # Connect to PostgreSQL and create database if it doesn't exist\n",
    "        self.conn = self.connect_to_db()\n",
    "        self.cur = self.conn.cursor()\n",
    "        self.create_table_if_not_exists()  # Ensure table exists\n",
    "\n",
    "        # Ollama API setup\n",
    "        self.url = 'http://127.0.0.1:11435/api/'\n",
    "        self.model_list = self.list_models()\n",
    "\n",
    "    def connect_to_db(self):\n",
    "        \"\"\"Connects to PostgreSQL and creates the database if it doesn't exist.\"\"\"\n",
    "        try:\n",
    "            # Connect to default 'postgres' database to check if target DB exists\n",
    "            temp_conn = psycopg2.connect(\n",
    "                dbname=\"postgres\",\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                host=self.db_host,\n",
    "                port=self.db_port\n",
    "            )\n",
    "            temp_conn.autocommit = True\n",
    "            temp_cur = temp_conn.cursor()\n",
    "\n",
    "            # Check if database exists\n",
    "            temp_cur.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{self.db_name}'\")\n",
    "            exists = temp_cur.fetchone()\n",
    "\n",
    "            if not exists:\n",
    "                print(f\"Database '{self.db_name}' not found. Creating it...\")\n",
    "                temp_cur.execute(f\"CREATE DATABASE {self.db_name}\")\n",
    "\n",
    "            temp_cur.close()\n",
    "            temp_conn.close()\n",
    "\n",
    "            # Now connect to the actual database\n",
    "            conn = psycopg2.connect(\n",
    "                dbname=self.db_name,\n",
    "                user=self.db_user,\n",
    "                password=self.db_password,\n",
    "                host=self.db_host,\n",
    "                port=self.db_port\n",
    "            )\n",
    "            print(f\"Connected to database: {self.db_name}\")\n",
    "            return conn\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Database connection failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def create_table_if_not_exists(self):\n",
    "        \"\"\"Ensures the generation history table exists in the database.\"\"\"\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS generation_history (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            model TEXT,\n",
    "            system_prompt TEXT,\n",
    "            prompt TEXT,\n",
    "            generated_text TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        );\n",
    "        \"\"\"\n",
    "        self.cur.execute(create_table_query)\n",
    "        self.conn.commit()\n",
    "        print(\"Table 'generation_history' is ready.\")\n",
    "\n",
    "    def generate_response(self, model, system_prompt, prompt, format=None):\n",
    "        \"\"\"\n",
    "        Sends a request to the LLM API and returns the response.\n",
    "        \"\"\"\n",
    "        if model in self.model_list:\n",
    "            self.model = model\n",
    "        else:\n",
    "            raise ValueError(f\"Model '{model}' not provided or not found in available models: {self.model_list}\")\n",
    "\n",
    "        url = \"http://127.0.0.1:11435/api/chat\"\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"keep_alive\": 0,\n",
    "            \"messages\": [\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': prompt}\n",
    "            ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        if format:\n",
    "            payload.update(format)\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            generated_text = response_data.get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "            # Store the generation in the database\n",
    "            self.save_to_db(model, system_prompt, prompt, generated_text)\n",
    "\n",
    "            return response_data  # Return the JSON response\n",
    "        else:\n",
    "            return {\"error\": f\"Request failed with status {response.status_code}\", \"details\": response.text}\n",
    "\n",
    "    def save_to_db(self, model, system_prompt, prompt, generated_text):\n",
    "        \"\"\"Saves the generated response to PostgreSQL.\"\"\"\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO generation_history (model, system_prompt, prompt, generated_text)\n",
    "        VALUES (%s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "        self.cur.execute(insert_query, (model, system_prompt, prompt, generated_text))\n",
    "        self.conn.commit()\n",
    "        print(\"Generation saved to database.\")\n",
    "\n",
    "    def list_models(self):\n",
    "        \"\"\"Retrieves the list of available models from Ollama API.\"\"\"\n",
    "        response = requests.get(f'{self.url}tags')\n",
    "        model_dict = {\n",
    "            model['name']: {\n",
    "                'model_name': model['name'],\n",
    "                'param_size': model['details']['parameter_size'],\n",
    "                'quant_level': model['details']['quantization_level']\n",
    "            }\n",
    "            for model in response.json()['models']\n",
    "        }\n",
    "        return model_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
