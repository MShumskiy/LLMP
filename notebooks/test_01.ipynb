{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "class ModelOperatorOllama():\n",
    "    def __init__(self, model:str):\n",
    "        self.url = 'http://127.0.0.1:11435/api/'\n",
    "        self.model_list = self.list_models()\n",
    "        \n",
    "        if model in self.model_list:\n",
    "            self.model = model\n",
    "        else:\n",
    "            raise ValueError(f\"Model '{model}' not provided or not found in available models: {self.model_list}\")\n",
    "        \n",
    "\n",
    "    def generate_response(self,system_prompt,prompt,format=None):\n",
    "        \"\"\"\n",
    "        Sends a request to the LLM API and returns the response.\n",
    "        \"\"\"\n",
    "        url=\"http://127.0.0.1:11435/api/chat\"\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {'role':'system',\n",
    "                'content':system_prompt\n",
    "                },\n",
    "                {'role':'user',\n",
    "                'content':prompt}\n",
    "                ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        if format:\n",
    "            payload.update(format)\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        \n",
    "        response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()  # Return the JSON response\n",
    "        else:\n",
    "            return {\"error\": f\"Request failed with status {response.status_code}\", \"details\": response.text}\n",
    "        \n",
    "    def unload_model(self):\n",
    "        \"\"\"\n",
    "        Sends a request to the LLM API to set keep_alive parameter.\n",
    "        \"\"\"\n",
    "        url=\"http://127.0.0.1:11435/api/chat\"\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"keep_alive\": 0,\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "        response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()  # Return the JSON response\n",
    "        else:\n",
    "            return {\"error\": f\"Request failed with status {response.status_code}\", \"details\": response.text}\n",
    "\n",
    "    def list_models(self):\n",
    "        \n",
    "        response = requests.get(f'{self.url}tags')\n",
    "        model_dict = {\n",
    "            model['name']: {'model_name': model['name'], 'param_size': model['details']['parameter_size']} for model in response.json()['models']\n",
    "    }\n",
    "        return model_dict\n",
    "\n",
    "# response = generate_response('you are a comedian',f'say 2', model=\"llama3.2\")\n",
    "# llmp = ModelOperatorOllama('phi4:latest')\n",
    "# system_prompt = 'you are a finance expert who can understand any piece of news and its implications on the markets. You excel at forex forecasting. Given the following piece of news, make your forecast'\n",
    "\n",
    "# prompt = df_news.iloc[0]['article_text']\n",
    "\n",
    "# format = {'format':{\n",
    "#     \"type\": \"object\",\n",
    "#     \"properties\": {\n",
    "#         \"currency\": {\n",
    "#             \"type\": \"string\",\n",
    "#             \"enum\": [\"USD\", \"EUR\", \"GBP\", \"JPY\", \"INR\"],\n",
    "#             \"description\": \"Currency code most affected by this news.\"\n",
    "#         },\n",
    "#         \"amount\": {\n",
    "#             \"type\": \"integer\",\n",
    "#             \"description\": \"Sign of the signal, 0 for negative and 1 for positive.\"\n",
    "#         },\n",
    "#         \"strenght\": {\n",
    "#             \"type\": \"number\",\n",
    "#             \"description\": \"strenght of the signal, 0 for minumum and 1 for maximum.\"\n",
    "#         },\n",
    "#         \"type\": {\n",
    "#             \"type\": \"string\",\n",
    "#             \"enum\": [\"descriptive\",\"predictive\"],\n",
    "#             \"description\": \"whether the signal refers to past or future\"\n",
    "#         }\n",
    "#     },\n",
    "#     \"required\": [\"currency\", \"amount\"],\n",
    "# }}\n",
    "\n",
    "# llmp.generate_response('','write numbers to 10')\n",
    "# response = llmp.generate_response(system_prompt,prompt,format)\n",
    "# llmp.list_models()\n",
    "# llmp.unload_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'phi4:latest',\n",
       " 'created_at': '2025-02-01T08:12:09.2726343Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': 'Sure! Here are the numbers from 1 to 10:\\n\\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\n\\nIf you need any more information or have questions about these numbers, feel free to ask!'},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 55488676100,\n",
       " 'load_duration': 27557120600,\n",
       " 'prompt_eval_count': 21,\n",
       " 'prompt_eval_duration': 2698000000,\n",
       " 'eval_count': 61,\n",
       " 'eval_duration': 24931000000}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmp = ModelOperatorOllama('phi4:latest')\n",
    "llmp.generate_response('','write numbers to 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'phi4:latest',\n",
       " 'created_at': '2025-02-01T08:12:29.5095742Z',\n",
       " 'message': {'role': 'assistant', 'content': ''},\n",
       " 'done_reason': 'unload',\n",
       " 'done': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmp.unload_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
